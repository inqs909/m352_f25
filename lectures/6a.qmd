---
title: "MGF"
subtitle: "Continuous Random Variables"
format:
  revealjs:
    navigation-mode: vertical
    controls-layout: bottom-right
    controls-tutorial: true
    incremental: false 
    chalkboard:
      src: chalkboard.json
      theme: whiteboard
      chalk-width: 4
editor: source
---

```{r}
#| include: false

knitr::opts_chunk$set(echo = T)

```

## Learning Outcomes

-   Moment Generating Functions

-   MGF Properties

## Moments

The $k$th moment is defined as the expectation of the random variable, raised to the $k$th power, defined as $E(X^k)$.

## Moment Generating Functions

The moment generating functions is used to obtain the $k$th moment. The mgf is defined as

$$
m(t) = E(e^{tX})
$$

The $k$th moment can be obtained by taking the $k$th derivative of the mgf, with respect to $t$, and setting $t$ equal to 0:

$$
E(X^k)=\frac{d^km(t)}{dt}\Bigg|_{t=0}
$$

## MGF Properties: Linearity

Let $X$ follow a distribution $f$, with the an MGF $M_X(t)$, the MGF of $Y=aX+b$ is given as

$$
M_Y(t) = e^{tb}M_X(at)
$$

## MGF Properties: Uniqueness

Let $X$ and $Y$ have the following distributions $F_X(x)$ and $F_Y(y)$ and MGFs $M_X(t)$ and $M_Y(t)$, respectively. $X$ and $Y$ have the same distribution $F_X(x)=F_Y(y)$ if and only if $M_X(t)=M_Y(t)$.

## Uniform Distribution MGF

$X\sim\mathrm{U(a,b)}$

$a<x<b$

$f_X(x) = \frac{1}{b-a}$

## Normal Distribution MGF

$X\sim\mathrm{N}(\mu, \sigma^2)$

$-\infty < x < \infty$

$f_X(x) = \frac{1}{\sqrt{2\pi \sigma^2}}\exp\left\{-\frac{(x-\mu)^2}{2\sigma^2}\right\}$

## Gamma Distribution MGF

$X\sim\mathrm{Gamma}(\alpha, \beta)$

$0<x<1$

$f_X(x)=\frac{1}{\Gamma(\alpha)\beta^\alpha}x^{\alpha-1}e^{-x/\beta}$

## $\chi^2$-Distribution MGF

$X\sim\chi^2_k$

$x>0$

$f_X(x)=\frac{x^{k/2-1}\exp\{-x/2\}}{2^{k/2}\Gamma(k/2)}$
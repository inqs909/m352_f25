{
  "hash": "3a8378aaff6ab455498ec96440a4a5e1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hypothesis Testing\"\nsubtitle: \"Linear and Generalized Linear Models\"\nformat:\n  revealjs:\n    width: 1200\n    scrollable: true\n    theme: [default, styles.scss]\n    controls-tutorial: true\n    navigation-mode: vertical\n    incremental: false \n    touch: false\n    controls: true\n    pointer:\n      pointerSize: 48\n    slide-number: true\n    sc-sb-title: h1\n    chalkboard:\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: false\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n\neditor: source\n\nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\n  \nauto-agenda:\n  bullets: numbered\n  clickable: true\n---\n\n\n\n# Statistical Inference\n\n## What is Statistical Inference?\n\n-   Drawing conclusions about a **population** based on a **sample**\n-   Population = entire group\n-   Sample = subset\n\n::: notes\nIntroduce the big idea: We want to make st\n:::\n\n## Two Main Types of Inference\n\n1.  Estimation\n2.  Hypothesis Testing\n\n::: notes\nWe'll be focusing on two fundamental techniques in inference. First, estimating population values (like the mean), and second, testing claims about the population.\n:::\n\n## Estimation\n\n-   **Point Estimate**: Single best guess (e.g., $\\hat \\beta_1$)\n-   **Interval Estimate**: Range likely to contain the true value\n\n::: notes\nPoint estimates are easy but not very informative. Intervals give us a sense of uncertainty, which is critical in inference.\n:::\n\n## Hypothesis Testing\n\n-   $H_0$: No effect or difference\\\n-   $H_1$: Some effect or difference\\\n-   We use sample data to support or reject $H_0$\n\n::: notes\nMention that $H_0$ is the default assumption. We only reject it if the data give us strong enough evidence.\n:::\n\n## Key Concepts and Tools\n\n-   Sampling Distribution\n-   Central Limit Theorem\n-   Standard Error\n\n::: notes\nThese three concepts are foundational. Understanding them helps us assess how reliable our estimates are.\n:::\n\n## p-values\n\n-   Probability of observing data as extreme as this if $H_0$ is true\n\n-   Misinterpretation of p-values is common.\n\n-   Emphasize: low p-value means data is unusual under $H_0$.\n\n## Confidence Intervals\n\n-   A range where we expect the true value to fall\n\n::: notes\nClarify interpretation: it's not about the probability the parameter is inside the interval, but about the method producing accurate intervals in the long run.\n:::\n\n# Hypothesis Testing\n\n## Hypothesis Tests\n\nHypothesis tests are used to test whether claims are valid or not. This is conducted by collecting data, setting the **Null** and **Alternative** Hypothesis.\n\n## Null Hypothesis $H_0$\n\nThe null hypothesis is the claim that is initially believed to be true. For the most part, it is always equal to the hypothesized value.\n\n## Alternative Hypothesis $H_1$\n\nThe alternative hypothesis contradicts the null hypothesis.\n\n## Example of Null and Alternative Hypothesis\n\nWe want to see if $\\beta$ is different from $\\beta^*$\n\n| Null Hypothesis        | Alternative Hypothesis |\n|------------------------|------------------------|\n| $H_0: \\beta=\\beta^*$   | $H_1: \\beta\\ne\\beta^*$ |\n| $H_0: \\beta\\le\\beta^*$ | $H_1: \\beta>\\beta^*$   |\n| $H_0: \\beta\\ge\\beta^*$ | $H_1: \\beta<\\beta^*$   |\n\n## One-Side vs Two-Side Hypothesis Tests\n\nNotice how there are 3 types of null and alternative hypothesis, The first type of hypothesis ($H_1:\\beta\\ne\\beta^*$) is considered a 2-sided hypothesis because the rejection region is located in 2 regions. The remaining two hypotheses are considered 1-sided because the rejection region is located on one side of the distribution.\n\n| Null Hypothesis        | Alternative Hypothesis | Side    |\n|------------------------|------------------------|---------|\n| $H_0: \\beta=\\beta^*$   | $H_1: \\beta\\ne\\beta^*$ | 2-Sided |\n| $H_0: \\beta\\le\\beta^*$ | $H_1: \\beta>\\beta^*$   | 1-Sided |\n| $H_0: \\beta\\ge\\beta^*$ | $H_1: \\beta<\\beta^*$   | 1-Sided |\n\n## Hypothesis Testing Steps\n\n1.  State $H_0$ and $H_1$\n2.  Choose $\\alpha$\n3.  Compute confidence interval/p-value\n4.  Make a decision\n\n::: notes\nWalk through the steps slowly with an example in mind. Emphasize that $\\alpha$ is a threshold, not the actual probability of error.\n:::\n\n## Rejection Region\n\n-   The rejection region is the set of all test statistic values that lead to rejecting $H_0$.\n\n-   It’s defined by a significance level ($\\alpha$) — the probability of rejecting $H_0$, when it’s actually true.\n\n## Rejection Region\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' fig-alt='A normal distribution demonstrating the rejection regions.' width=960}\n:::\n:::\n\n\n# Decision Making\n\n## Decision Making\n\nHypothesis Testing will force you to make a decision: Reject $H_0$ **OR** Fail to Reject $H_0$\n\n::: fragment\nReject $H_0$: The effect seen is not due to random chance, there is a process contributing to the effect.\n:::\n\n::: fragment\nFail to Reject $H_0$: The effect seen is due to random chance. Random sampling is the reason why an effect is displayed, not an underlying process.\n:::\n\n## Decision Making: Test Statistic\n\n::::: columns\n::: {.column width=\"50%\"}\n### $\\phi$ known\n\n$$\nts = \\frac{\\hat\\beta_j - \\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim N(0,1) \n$$\n:::\n\n::: {.column width=\"50%\"}\n### $\\phi$ unknown\n\n$$\nts = \\frac{\\hat\\beta_j-\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim t_{n-p}\n$$\n:::\n:::::\n\n\n## Decision Making: P-Value\n\n**Two-Sided Test**\n\n$$\nP(T > |ts|) = \\int^\\infty_{ts} f(t) dt + \\int_{-\\infty}^{ts} f(t) dt\n$$\n\n**One-Sided Test**\n$$\nP(T > ts) = \\int^\\infty_{ts} f(t) dt\n$$\n\nOR\n$$\nP(T < ts) = \\int_{-\\infty}^{ts} f(t) dt\n$$\n\n\n## Rejection Region\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' fig-alt='A normal distribution demonstrating the rejection regions.' width=960}\n:::\n:::\n\n\n## Decision Making: P-Value\n\nThe p-value approach is one of the most common methods to report significant results. It is easier to interpret the p-value because it provides the probability of observing our test statistics, or something more extreme, given that the null hypothesis is true.\n\n::: fragment\n**If** $p < \\alpha$, then you reject $H_0$; otherwise, you will fail to reject $H_0$.\n:::\n\n## Significance Level $\\alpha$\n\nThe significance level $\\alpha$ is the probability you will reject the null hypothesis given that it was true.\n\n::: fragment\nIn other words, $\\alpha$ is the error rate that a researcher controls.\n:::\n\n::: fragment\nTypically, we want this error rate to be small ($\\alpha = 0.05$).\n:::\n\n# Model Inference\n\n## Model Inference\n\n**Model Inference** is the act of conducting a hypothesis test on the entire model (line). We do this to determine if the fully explained model is **significantly** different from the smaller models or average.\n\n::: fragment\nModel inference determines if more variation is explained by including more predictors.\n:::\n\n## Model inference\n\n-   We will conduct model inference to determine if different models are better at explaining variation. Both Linear and Logistic Regression have techniques to test different models.\n\n\n## Full and Reduced Model\n\n::::: columns\n::: column\n### Full Model\n\n$$\nY =  \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p\n$$\n:::\n\n::: column\n### Reduced Model\n\n$$\nY =  \\beta_0 + \\beta_1 X_1\n$$\n:::\n:::::\n\n## Null and Alt Hypothesis\n\n$H_0$: The fully-parameterized model does not explain more variation than the reduced model.\n\n$H_a$: The fully-parameterized model does explain more variation than the reduced model.\n\n# Confidence Intervals\n\n## Confidence Intervals\n\n-   A confidence interval gives a **range of plausible values** that captures population parameter.\n-   It reflects **uncertainty** in point estimates from sample data.\n\n::: notes\nIntroduce confidence intervals as the natural next step after understanding sampling variability and standard error. Emphasize that point estimates are useful, but intervals give a more complete picture.\n:::\n\n## CI: Formula\n\n$$\nPE \\pm CV \\times SE\n$$\n\n- $PE$: Point estimate ($\\hat \\beta$)\n- $CV$: Critical Value $P(X > CV) + P(X < -CV) = \\alpha$\n- $SE$: Standard Error of $\\hat \\beta$\n\n\n\n::: fragment\n\n$$\n(LB = PE - CV \\times SE, UB = PE + CV \\times SE)\n$$\n\n:::\n\n## Interpretation\n\n> \"We are 95% confident that the true mean lies between A and B.\"\n\n-   This does **not** mean there's a 95% chance the mean is in that interval.\n-   It means: if we repeated the sampling process many times, **95% of the intervals would contain the true value**.\n\n::: notes\nThis is one of the most common misconceptions. Clarify that the confidence is in the *method*, not any one interval.\n:::\n\n## CI Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n## Factors Affecting CI Width\n\n-   Sample size ($n$): larger $n$ → narrower CI\\\n-   Standard deviation ($s$ or $\\sigma$): more variability → wider CI\\\n-   Confidence level: higher confidence → wider CI\n\n::: notes\nUse this to summarize what controls how “precise” our confidence interval is. Give examples of each.\n:::\n\n## Decision Making: Confidence Interval Approach\n\nThe confidence interval approach can evaluate a hypothesis test where the alternative hypothesis is $\\beta\\ne\\beta^*$. The confidence interval approach will result in a lower and upper bound denoted as: $(LB, UB)$.\n\n::: fragment\n**If** $\\beta^*$ is in $(LB, UB)$, then you fail to reject $H_0$. If $\\beta^*$ is not in $(LB,UB)$, then you reject $H_0$.\n:::\n\n# Power Analysis\n\n## What is Statistical Power\n\n-   **Statistical Power** is the probability of correctly rejecting a false null hypothesis.\n-   In other words, it's the chance of **detecting a real effect** when it exists.\n\n## Why Power Matters\n\n-   Low power → high risk of **Type II Error** (false negatives)\n-   High power → better chance of finding true effects\n-   Common threshold: **80% power**\n\n## Errors in Inference\n\n|         |                               |                         |\n|:--------|:------------------------------|:------------------------|\n| Type I  | Reject $H_0$ when true        | False positive          |\n| Type II | Don't reject $H_0$ when false | False negative          |\n| Power   | $1 - P(\\text{Type II})$       | Detecting a true effect |\n\n::: notes\nPower is often overlooked. It's about how sensitive the test is to real effects. Larger samples increase power.\n:::\n\n## Type I Error (False Positive)\n\n-   **Rejecting** $H_0$ when it is actually true\n-   Probability = $\\alpha$ (significance level)\n\n::: notes\nType I errors happen when we detect an effect that doesn't really exist. This is controlled by our chosen alpha level.\n:::\n\n## Type II Error (False Negative)\n\n-   **Failing to reject** $H_0$ when it is actually false\n-   Probability = $\\beta$\n-   Power = $1 - \\beta$\n\n::: notes\nType II errors are often due to small sample sizes or high variability. Power analysis helps us plan to avoid these.\n:::\n\n## Balancing Errors\n\n-   Lowering $\\alpha$ reduces Type I errors, but **increases** risk of Type II errors.\n-   To reduce both:\n    -   Increase sample size\n    -   Use more appropriate statistical tests\n\n::: notes\nThere's a trade-off between these errors. We can't eliminate both, but we can **manage** the risk based on the consequences of each type.\n:::\n\n## What Affects Power?\n\n1.  **Effect Size**\n    -   Bigger effects are easier to detect\n2.  **Sample Size (**$n$)\n    -   Larger samples reduce standard error\n3.  **Significance Level (**$\\alpha$)\n    -   Higher $\\alpha$ increases power (but riskier!)\n4.  **Variability**\n    -   Less noise in data = better power\n\n## Boosting Power\n\n-   Power = Probability of rejecting $H_0$ when it's false\n-   Helps avoid **Type II Errors**\n-   Driven by:\n    -   Sample size\n    -   Effect size\n    -   $\\alpha$\n    -   Variability\n-   Aim for **80% or higher**\n\n# Model Conditions\n\n## Model Conditions\n\nWhen we are conducting inference with regression models, we will have to check the following conditions:\n\n-   Linearity\n-   Independence\n-   Probability Assumption\n-   Equal Variances\n-   Multicollinearity (for Multi-Regression)\n\n## Linearity\n\nThere must be a linear relationship between both the outcome variable (y) and a set of predictors ($x_1$, $x_2$, ...).\n\n## Independence\n\nThe data points must not influence each other.\n\n## Probability Assumption\n\nThe model errors (also known as residuals) must follow a specified distribution.\n\n-   Linear Regression: Normal Distribution\n\n-   Logistic Regression: Binomial Distribution\n\n## Equal Variances\n\nThe variability of the data points must be the same for all predictor values.\n\n## Residuals\n\nResiduals are the errors between the observed value and the estimated model. Common residuals include\n\n-   Raw Residual\n\n-   Standardized Residuals\n\n-   Jackknife (studentized) Residuals\n\n-   Deviance Residuals\n\n-   Quantized Residuals\n\n## Influential Measurements\n\nInfluential measures are statistics that determine how much a data point affects the model. Common influential measures are\n\n-   Leverages\n\n-   Cook's Distance\n\n## Raw Residuals\n\n$$\n\\hat r_i = y_i - \\hat y_i\n$$\n\n## Residual Analysis\n\nA residual analysis is used to test the assumptions of linear regression.\n\n## QQ Plot\n\nA qq (quantile-quantile) plot will plot the estimated quantiles of the residuals against the theoretical quantiles from a normal distribution function. If the points from the qq-plot lie on the $y=x$ line, it is said that the residuals follow a normal distribution.\n\n## Residual vs Fitted Plot\n\nThis plot allows you to assess the linearity, constant variance, and identify potential outliers. Create a scatter plot between the fitted values (x-axis)\n\n## Penguins: Example\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-6-2.png){width=960}\n:::\n:::\n\n\n## Heart: Example\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-8-2.png){width=960}\n:::\n:::\n",
    "supporting": [
      "14_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}